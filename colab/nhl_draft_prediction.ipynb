{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 6.6 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.1-cp311-cp311-win_amd64.whl (16.6 MB)\n",
      "     --------------------------------------- 16.6/16.6 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 14.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timot\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "     -------------------------------------- 505.5/505.5 kB 5.3 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     ------------------------------------- 345.4/345.4 kB 10.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "     ------------------------------------ 385.0/385.0 MB 420.4 kB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     ------------------------------------ 133.7/133.7 kB 656.7 kB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     -------------------------------------- 57.5/57.5 kB 150.9 kB/s eta 0:00:00\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 11.2 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Downloading ml_dtypes-0.4.0-cp311-cp311-win_amd64.whl (126 kB)\n",
      "     ------------------------------------ 126.8/126.8 kB 677.4 kB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\timot\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\timot\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\timot\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.65.2-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 8.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting keras>=3.2.0\n",
      "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.14.0-cp311-cp311-win_amd64.whl (44.7 MB)\n",
      "     ---------------------------------------- 44.7/44.7 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 301.8/301.8 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.8/65.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting rich\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "     -------------------------------------- 240.7/240.7 kB 7.4 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.12.1-cp311-cp311-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 268.5/268.5 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "     ---------------------------------------- 99.9/99.9 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "     ---------------------------------------- 66.8/66.8 kB 3.8 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "     -------------------------------------- 121.4/121.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "     -------------------------------------- 163.0/163.0 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "     ------------------------------------ 105.4/105.4 kB 508.8 kB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "     ------------------------------------- 227.3/227.3 kB 14.5 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\timot\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, typing-extensions, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, numpy, mdurl, MarkupSafe, markdown, joblib, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, scipy, requests, pandas, optree, opt-einsum, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, scikit-learn, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.7.4 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.2 h5py-3.11.0 idna-3.7 joblib-1.4.2 keras-3.4.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 pandas-2.2.2 protobuf-4.25.4 pytz-2024.1 requests-2.32.3 rich-13.7.1 scikit-learn-1.5.1 scipy-1.14.0 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 threadpoolctl-3.5.0 typing-extensions-4.12.2 tzdata-2024.1 urllib3-2.2.2 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "%pip install pandas numpy tensorflow scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  year  overall_pick                 team            player nationality  \\\n",
      "0   1  2022             1   Montreal Canadiens  Juraj Slafkovsky          SK   \n",
      "1   2  2022             2    New Jersey Devils       Simon Nemec          SK   \n",
      "2   3  2022             3      Arizona Coyotes      Logan Cooley          US   \n",
      "3   4  2022             4       Seattle Kraken      Shane Wright          CA   \n",
      "4   5  2022             5  Philadelphia Flyers   Cutter Gauthier          SE   \n",
      "\n",
      "  position   age  to_year                           amateur_team  ...  points  \\\n",
      "0       LW  18.0      NaN                          TPS (Finland)  ...     NaN   \n",
      "1        D  18.0      NaN                    HK Nitra (Slovakia)  ...     NaN   \n",
      "2        C  18.0      NaN  USA U-18 Development Team (USDP/USHL)  ...     NaN   \n",
      "3        C  18.0      NaN              Kingston Frontenacs (OHL)  ...     NaN   \n",
      "4       LW  18.0      NaN  USA U-18 Development Team (USDP/USHL)  ...     NaN   \n",
      "\n",
      "   plus_minus  penalties_minutes  goalie_games_played  goalie_wins  \\\n",
      "0         NaN                NaN                  NaN          NaN   \n",
      "1         NaN                NaN                  NaN          NaN   \n",
      "2         NaN                NaN                  NaN          NaN   \n",
      "3         NaN                NaN                  NaN          NaN   \n",
      "4         NaN                NaN                  NaN          NaN   \n",
      "\n",
      "   goalie_losses  goalie_ties_overtime  save_percentage  \\\n",
      "0            NaN                   NaN              NaN   \n",
      "1            NaN                   NaN              NaN   \n",
      "2            NaN                   NaN              NaN   \n",
      "3            NaN                   NaN              NaN   \n",
      "4            NaN                   NaN              NaN   \n",
      "\n",
      "   goals_against_average  point_shares  \n",
      "0                    NaN           NaN  \n",
      "1                    NaN           NaN  \n",
      "2                    NaN           NaN  \n",
      "3                    NaN           NaN  \n",
      "4                    NaN           NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12250 entries, 0 to 12249\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     12250 non-null  int64  \n",
      " 1   year                   12250 non-null  int64  \n",
      " 2   overall_pick           12250 non-null  int64  \n",
      " 3   team                   12249 non-null  object \n",
      " 4   player                 12250 non-null  object \n",
      " 5   nationality            12246 non-null  object \n",
      " 6   position               12223 non-null  object \n",
      " 7   age                    8291 non-null   float64\n",
      " 8   to_year                5246 non-null   float64\n",
      " 9   amateur_team           12250 non-null  object \n",
      " 10  games_played           5246 non-null   float64\n",
      " 11  goals                  5246 non-null   float64\n",
      " 12  assists                5246 non-null   float64\n",
      " 13  points                 5246 non-null   float64\n",
      " 14  plus_minus             5234 non-null   float64\n",
      " 15  penalties_minutes      5246 non-null   float64\n",
      " 16  goalie_games_played    490 non-null    float64\n",
      " 17  goalie_wins            488 non-null    float64\n",
      " 18  goalie_losses          488 non-null    float64\n",
      " 19  goalie_ties_overtime   488 non-null    float64\n",
      " 20  save_percentage        488 non-null    float64\n",
      " 21  goals_against_average  490 non-null    float64\n",
      " 22  point_shares           5246 non-null   float64\n",
      "dtypes: float64(15), int64(3), object(5)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "                 id          year  overall_pick          age      to_year  \\\n",
      "count  12250.000000  12250.000000  12250.000000  8291.000000  5246.000000   \n",
      "mean    6125.500000   1996.250122    116.633143    18.675793  2004.222074   \n",
      "std     3536.414733     14.733847     72.030642     1.328110    14.303401   \n",
      "min        1.000000   1963.000000      1.000000    16.000000  1968.000000   \n",
      "25%     3063.250000   1984.000000     55.000000    18.000000  1993.000000   \n",
      "50%     6125.500000   1996.000000    112.000000    18.000000  2006.000000   \n",
      "75%     9187.750000   2008.000000    174.000000    19.000000  2017.750000   \n",
      "max    12250.000000   2022.000000    293.000000    37.000000  2022.000000   \n",
      "\n",
      "       games_played        goals      assists       points   plus_minus  \\\n",
      "count   5246.000000  5246.000000  5246.000000  5246.000000  5234.000000   \n",
      "mean     305.384102    50.858940    85.037743   135.896493    -2.282767   \n",
      "std      346.748283    94.060512   144.246996   232.821818    51.247311   \n",
      "min        1.000000     0.000000     0.000000     0.000000  -257.000000   \n",
      "25%       25.000000     0.000000     2.000000     3.000000   -17.000000   \n",
      "50%      151.500000     9.000000    18.000000    28.000000    -2.000000   \n",
      "75%      521.000000    56.000000   107.000000   166.000000     1.000000   \n",
      "max     1779.000000   780.000000  1249.000000  1921.000000   722.000000   \n",
      "\n",
      "       penalties_minutes  goalie_games_played  goalie_wins  goalie_losses  \\\n",
      "count        5246.000000           490.000000   488.000000     488.000000   \n",
      "mean          245.281357           181.300000    77.971311      69.196721   \n",
      "std           409.171631           229.950359   109.048598      85.677984   \n",
      "min             0.000000             1.000000     0.000000       0.000000   \n",
      "25%             8.000000             7.000000     2.000000       3.000000   \n",
      "50%            65.000000            74.000000    23.500000      32.000000   \n",
      "75%           311.000000           294.000000   117.000000     112.250000   \n",
      "max          3971.000000          1266.000000   691.000000     397.000000   \n",
      "\n",
      "       goalie_ties_overtime  save_percentage  goals_against_average  \\\n",
      "count            488.000000       488.000000             490.000000   \n",
      "mean              21.315574         0.886836               3.375857   \n",
      "std               28.479086         0.051013               1.797891   \n",
      "min                0.000000         0.500000               0.000000   \n",
      "25%                1.000000         0.875750               2.710000   \n",
      "50%                9.000000         0.895000               3.100000   \n",
      "75%               33.000000         0.908000               3.697500   \n",
      "max              154.000000         1.000000              27.270000   \n",
      "\n",
      "       point_shares  \n",
      "count   5246.000000  \n",
      "mean      17.359112  \n",
      "std       29.115392  \n",
      "min      -10.100000  \n",
      "25%        0.100000  \n",
      "50%        3.300000  \n",
      "75%       22.400000  \n",
      "max      242.700000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../data/nhldraft.csv')\n",
    "\n",
    "# Explore the data\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "data = data.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data, columns=['team', 'nationality', 'position', 'amateur_team'])\n",
    "\n",
    "# Split the data into features and target\n",
    "features = data.drop(['player'], axis=1)  # Dropping the player column as it is not used for predictions\n",
    "target = data['overall_pick']  # Assuming we want to predict the overall pick position\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize/scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 13096.4736 - mae: 96.3819 - val_loss: 12130.6113 - val_mae: 88.8310\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12045.2734 - mae: 91.1363 - val_loss: 11583.9053 - val_mae: 85.8422\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12234.1562 - mae: 90.3065 - val_loss: 10921.8945 - val_mae: 82.1884\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11779.3760 - mae: 87.7689 - val_loss: 10147.1152 - val_mae: 77.9405\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9735.6318 - mae: 76.7808 - val_loss: 9282.3467 - val_mae: 73.2105\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7504.1597 - mae: 65.1183 - val_loss: 8311.0234 - val_mae: 68.4408\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5271.9624 - mae: 53.7154 - val_loss: 7390.8159 - val_mae: 63.9311\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3938.9163 - mae: 45.7729 - val_loss: 6610.9155 - val_mae: 62.0544\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1858.9218 - mae: 32.1055 - val_loss: 6095.1348 - val_mae: 61.3945\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1479.5701 - mae: 30.0856 - val_loss: 5804.1533 - val_mae: 60.8360\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1102.6423 - mae: 26.2730 - val_loss: 5664.4888 - val_mae: 60.2876\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 994.4050 - mae: 24.2190 - val_loss: 5573.8032 - val_mae: 59.6721\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 804.0747 - mae: 21.4582 - val_loss: 5477.3032 - val_mae: 58.9978\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 574.6492 - mae: 17.2598 - val_loss: 5383.7461 - val_mae: 58.2809\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 539.7225 - mae: 16.3504 - val_loss: 5254.1045 - val_mae: 57.5363\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 473.2727 - mae: 14.9432 - val_loss: 5135.5137 - val_mae: 56.7708\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 474.7610 - mae: 14.5385 - val_loss: 5031.0820 - val_mae: 56.1094\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 385.5723 - mae: 12.9882 - val_loss: 4955.6826 - val_mae: 55.4795\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 327.7388 - mae: 11.5120 - val_loss: 4867.9126 - val_mae: 54.8354\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 319.1378 - mae: 11.6396 - val_loss: 4803.2378 - val_mae: 54.3476\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 268.8487 - mae: 10.5606 - val_loss: 4748.7671 - val_mae: 53.9135\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 267.4496 - mae: 9.8777 - val_loss: 4692.3374 - val_mae: 53.4977\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 219.5793 - mae: 8.6725 - val_loss: 4626.2905 - val_mae: 52.9852\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 206.5252 - mae: 8.6652 - val_loss: 4551.0273 - val_mae: 52.4593\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 175.9312 - mae: 7.8099 - val_loss: 4501.9810 - val_mae: 52.0354\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 191.4698 - mae: 8.2408 - val_loss: 4459.3877 - val_mae: 51.7182\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 176.9707 - mae: 7.4980 - val_loss: 4403.7310 - val_mae: 51.3501\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 136.8389 - mae: 6.9144 - val_loss: 4365.3066 - val_mae: 51.0565\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 149.2408 - mae: 7.1575 - val_loss: 4323.7754 - val_mae: 50.7983\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 140.5448 - mae: 6.7877 - val_loss: 4275.1611 - val_mae: 50.4969\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 111.5859 - mae: 5.7484 - val_loss: 4237.0171 - val_mae: 50.2286\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141.2326 - mae: 6.4279 - val_loss: 4201.3384 - val_mae: 49.9658\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 124.0108 - mae: 6.1143 - val_loss: 4158.3022 - val_mae: 49.6919\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 101.6070 - mae: 5.3503 - val_loss: 4117.0024 - val_mae: 49.4399\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 108.6766 - mae: 5.8657 - val_loss: 4082.0757 - val_mae: 49.2155\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 83.3581 - mae: 4.7894 - val_loss: 4051.5071 - val_mae: 48.9854\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 101.6060 - mae: 5.2127 - val_loss: 4009.1035 - val_mae: 48.7029\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 89.9520 - mae: 5.0849 - val_loss: 3967.8486 - val_mae: 48.4513\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 83.0970 - mae: 4.8276 - val_loss: 3935.6335 - val_mae: 48.2476\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 71.3546 - mae: 4.6211 - val_loss: 3905.2090 - val_mae: 48.0148\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 77.3488 - mae: 4.5550 - val_loss: 3869.9255 - val_mae: 47.7649\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 73.2434 - mae: 4.2313 - val_loss: 3846.0049 - val_mae: 47.5873\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 81.3717 - mae: 4.8279 - val_loss: 3811.5708 - val_mae: 47.3698\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71.4512 - mae: 4.5619 - val_loss: 3780.3083 - val_mae: 47.1357\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 57.2644 - mae: 3.8330 - val_loss: 3747.0320 - val_mae: 46.8698\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2624 - mae: 3.1462 - val_loss: 3724.2012 - val_mae: 46.7284\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.1993 - mae: 3.3087 - val_loss: 3695.0198 - val_mae: 46.5276\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.9258 - mae: 3.7537 - val_loss: 3665.0144 - val_mae: 46.2945\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 45.2599 - mae: 3.3263 - val_loss: 3641.0049 - val_mae: 46.0973\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 48.6181 - mae: 3.3056 - val_loss: 3614.0000 - val_mae: 45.8870\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.8652 - mae: 3.2457 - val_loss: 3583.2429 - val_mae: 45.6859\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.3842 - mae: 2.9422 - val_loss: 3566.0901 - val_mae: 45.5499\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 40.6764 - mae: 3.0353 - val_loss: 3537.9597 - val_mae: 45.3587\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.8393 - mae: 2.7341 - val_loss: 3512.1238 - val_mae: 45.1923\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 38.3054 - mae: 2.9984 - val_loss: 3483.9482 - val_mae: 45.0160\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.1940 - mae: 2.8355 - val_loss: 3465.4568 - val_mae: 44.8769\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.7043 - mae: 2.7031 - val_loss: 3443.6125 - val_mae: 44.7333\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.7122 - mae: 2.5319 - val_loss: 3421.8474 - val_mae: 44.6069\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.9560 - mae: 2.7562 - val_loss: 3396.2000 - val_mae: 44.4268\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.1635 - mae: 2.3580 - val_loss: 3378.9927 - val_mae: 44.2743\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.1888 - mae: 2.0762 - val_loss: 3357.0405 - val_mae: 44.1449\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15.8348 - mae: 1.8052 - val_loss: 3332.5547 - val_mae: 43.9822\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.6270 - mae: 2.1982 - val_loss: 3314.6372 - val_mae: 43.8431\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.1916 - mae: 2.1271 - val_loss: 3292.9507 - val_mae: 43.6840\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.9258 - mae: 1.6372 - val_loss: 3269.6438 - val_mae: 43.5212\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.9073 - mae: 2.1503 - val_loss: 3249.6360 - val_mae: 43.3729\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.9032 - mae: 1.8593 - val_loss: 3227.9890 - val_mae: 43.2076\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.6828 - mae: 1.5216 - val_loss: 3209.7666 - val_mae: 43.0870\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 17.1811 - mae: 1.8781 - val_loss: 3188.9272 - val_mae: 42.9430\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15.3470 - mae: 1.6790 - val_loss: 3176.6365 - val_mae: 42.8579\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.6904 - mae: 1.4049 - val_loss: 3157.7793 - val_mae: 42.7223\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.9611 - mae: 1.5074 - val_loss: 3142.5325 - val_mae: 42.6156\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.9459 - mae: 1.5499 - val_loss: 3123.5466 - val_mae: 42.4683\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.6647 - mae: 1.4621 - val_loss: 3106.2446 - val_mae: 42.3433\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.9117 - mae: 1.4397 - val_loss: 3095.3523 - val_mae: 42.2570\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 14.6799 - mae: 1.5964 - val_loss: 3079.4895 - val_mae: 42.1485\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.2364 - mae: 1.3258 - val_loss: 3066.4570 - val_mae: 42.0725\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10.5723 - mae: 1.3950 - val_loss: 3056.8169 - val_mae: 41.9933\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2871 - mae: 1.1718 - val_loss: 3038.7063 - val_mae: 41.8665\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8775 - mae: 1.1648 - val_loss: 3027.1968 - val_mae: 41.7526\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0461 - mae: 1.1982 - val_loss: 3013.3267 - val_mae: 41.6450\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8963 - mae: 1.1016 - val_loss: 3002.2397 - val_mae: 41.5666\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.6043 - mae: 0.9705 - val_loss: 2990.8982 - val_mae: 41.4856\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.1253 - mae: 0.9734 - val_loss: 2979.6335 - val_mae: 41.4042\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.6707 - mae: 0.9409 - val_loss: 2968.5354 - val_mae: 41.3077\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.6884 - mae: 0.9682 - val_loss: 2957.1838 - val_mae: 41.2211\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8720 - mae: 0.8327 - val_loss: 2947.9641 - val_mae: 41.1494\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.6976 - mae: 0.9556 - val_loss: 2935.3018 - val_mae: 41.0374\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9357 - mae: 0.8193 - val_loss: 2926.8562 - val_mae: 40.9896\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.8963 - mae: 0.9977 - val_loss: 2915.1589 - val_mae: 40.8981\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7363 - mae: 0.6855 - val_loss: 2905.1655 - val_mae: 40.8166\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2578 - mae: 0.8899 - val_loss: 2896.1335 - val_mae: 40.7492\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5507 - mae: 0.7171 - val_loss: 2884.6375 - val_mae: 40.6582\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.7331 - mae: 0.6943 - val_loss: 2876.6592 - val_mae: 40.6011\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3584 - mae: 0.8420 - val_loss: 2871.9895 - val_mae: 40.5617\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4680 - mae: 0.7037 - val_loss: 2862.9473 - val_mae: 40.4880\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2884 - mae: 0.6575 - val_loss: 2856.9473 - val_mae: 40.4331\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8997 - mae: 0.7330 - val_loss: 2846.6577 - val_mae: 40.3615\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7899 - mae: 0.6582 - val_loss: 2840.6750 - val_mae: 40.3283\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6721 - mae: 0.6854 - val_loss: 2830.0374 - val_mae: 40.2576\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2962.4221 - mae: 42.1190 \n",
      "Mean Absolute Error: 43.295406341552734\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing data\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('draft_prediction_model.h5')\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predicted_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})\n",
    "predicted_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytesseract opencv-python pillow\n",
    "import pytesseract\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Load the image\n",
    "image_path = '/mnt/data/image.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use OCR to extract text\n",
    "text = pytesseract.image_to_string(gray)\n",
    "\n",
    "# Print extracted text\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
